from datetime import datetime, timedelta
from transformers import pipeline


STYLES = {
    # Great format to run with screenshots
    1: [
        "Fontsize={font_size},",
        "PrimaryColour={primary_color},",
        "OutlineColour=&H40000000,",
        "Bold={bold},",
        "Alignment=6,",
        "MarginL=0,",
        "MarginR=0,",
        "MarginV=200",
    ],
    # Centerd Bold Text
    2: [
        "Fontsize={font_size},",
        "PrimaryColour=&HFFFFFF&,",
        "OutlineColour=&H40000000,",
        "Bold={bold},",
        "Alignment=10,",
        "MarginL=0,",
        "MarginR=0,",
        "MarginV=0",
    ],
}


def get_subtitles_style(
    primary_color: str = "&HFFFFFF&",
    font_size: float = 18,
    bold: bool = True,
    desired_style: int = 1,
):
    """
    Get subtitles style.
    :param primary_color: Primary color.
    :param font_size: Font size.
    :param bold: Bold text.
    :param desired_style: Desired style.
    :return: Subtitles style.
    """
    return "".join(STYLES[desired_style]).format(
        primary_color=primary_color, font_size=font_size, bold=bold
    )


def generate_srt(subtitles: list) -> str:
    """
    Generate an SRT file from a list of timestamps of words
    :param subtitles: Subtitles list.
    :return: .srt file contents
    """
    timestamp_format = datetime.strptime(
        "00:00:00,000", "%H:%M:%S,%f"
    )  # Null element of addition to keep the timestamp format
    srt = []
    for i, subtitle in enumerate(subtitles):
        start_time = (subtitle["start_time"] + timestamp_format).strftime(
            "%H:%M:%S,%f"
        )[:-3]
        end_time = (subtitle["end_time"] + timestamp_format).strftime("%H:%M:%S,%f")[
            :-3
        ]
        words = subtitle["words"]

        srt.append(f"{i+1}")
        srt.append(f"{start_time} --> {end_time}")
        srt.append(" ".join(words) + "\n")

    return "\n".join(srt)


def append_segment_to_subtitles(subtitles: list, segment: tuple) -> list:
    """
    Append segment to subtitles.
    :param subtitles: Subtitles list.
    :param segment: Segment to append.
    :return: Subtitles list.
    """
    # Calculate end_time for each word
    start_time = timedelta(seconds=segment["timestamp"][0])
    end_time = timedelta(seconds=segment["timestamp"][1])
    # Create subtitle for each word
    subtitle = {
        "start_time": start_time,
        "end_time": end_time,
        "words": [segment["text"]],
    }
    subtitles.append(subtitle)
    return subtitles


def transcribe_audio(audio_path: str, srt_path: str) -> None:
    """
    Transcribe audio file to SRT file.
    :param audio_path: Path to the audio file.
    :param srt_path: Path to the SRT file.
    :param word_by_word: If True, the subtitles will be generated by each word.
    """
    pipe = pipeline(
        "automatic-speech-recognition",
        "openai/whisper-large-v3",
        generate_kwargs={"language": "spanish"},
    )

    pipe.model = pipe.model.to_bettertransformer()

    outputs = pipe(audio_path, chunk_length_s=30, batch_size=24, return_timestamps=True)
    chunks = outputs["chunks"]
    subtitles = []
    for chunk in chunks:
        subtitles = append_segment_to_subtitles(subtitles, chunk)

    # Gererate the SRT File
    srt_content = generate_srt(subtitles)

    # Write the SRT File
    with open(srt_path, "w", encoding="utf-8") as file:
        file.write(srt_content)
